import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import shap
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, balanced_accuracy_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV
from sklearn.decomposition import PCA
from sklearn.feature_selection import RFECV
import mlflow
import mlflow.sklearn



def clean_df_tst_na(df_full):
    index_correct_tst = np.where((df_full['tst'] < 12) & (df_full['tst'] > 3))[0]
    df_correct_tst = df_full.iloc[index_correct_tst, :]
    df_clean = df_correct_tst.fillna(0)
    df_clean = df_clean.drop(columns=df_clean.columns[(df_clean == 0).all()])
    return df_clean

def calculate_stat_demograpic(df_clean, df_healthy):
    num_subjects = len(np.unique(df_clean['Subject ID'].to_list()))
    num_non_pd = len(np.unique(df_clean.loc[df_clean['PD'] == 0, 'Subject ID'].to_list()))
    num_pd = len(np.unique(df_clean.loc[df_clean['PD'] == 1, 'Subject ID'].to_list()))
    num_non_pd_rbd = len(np.unique(df_clean.loc[(df_clean['RBD'] == 1) & (df_clean['PD'] == 0), 'Subject ID'].to_list()))
    num_pd_rbd = len(np.unique(df_clean.loc[(df_clean['RBD'] == 1) & (df_clean['PD'] == 1), 'Subject ID'].to_list()))
    night_count_non_pd = df_healthy.groupby('Subject ID').count()
    subjects_label_non_pd = df_healthy.iloc[:,0:3].groupby('Subject ID').max()

    ''' Calculate stat demograpic '''
    pd_cohort = pd.read_excel('DOD_subjects_cohort.xlsx')
    pd_cohort = pd_cohort[pd_cohort['Axivity file lab'] == 1]
    pd_cohort_non_pd = pd_cohort[pd_cohort['PD'] == 0]
    pd_cohort_non_pd_rbd = pd_cohort_non_pd[pd_cohort_non_pd['RBD test'] > 0]
    pd_cohort_non_pd_no_rbd = pd_cohort_non_pd[pd_cohort_non_pd['RBD test'] == 0]
    pd_cohort_non_pd_rbdq = pd_cohort_non_pd.loc[:,['Subject ID','RBDQ']]
    pd_cohort_non_pd_rbdq.reset_index(drop=True, inplace=True)
    female_num_rbd = np.sum(pd_cohort_non_pd_rbd.iloc[:,16]==1)
    female_num_no_rbd = np.sum(pd_cohort_non_pd_no_rbd.iloc[:, 16] == 1)
    data = [[female_num_no_rbd, 58 - female_num_no_rbd], [female_num_rbd, 15 -female_num_rbd]]
    chi2_stat_sex, p_chi2_sex, dof, expected = stats.chi2_contingency(data)
    t_stat_age, p_ttest_age, u_stat_age, p_mann_age, mean_no_rbd_age, std_no_rbd_age, mean_rbd_age, std_rbd_age = calculate_stat_metadata(pd_cohort_non_pd_no_rbd, pd_cohort_non_pd_rbd,'Age')
    t_stat_updrs, p_ttest_updrs, u_stat_updrs, p_mann_updrs,  mean_no_rbd_updrs, std_no_rbd_updrs, mean_rbd_updrs, std_rbd_updrs = calculate_stat_metadata(pd_cohort_non_pd_no_rbd, pd_cohort_non_pd_rbd, 'UPDRS III')
    t_stat_moca, p_ttest_moca, u_stat_moca, p_mann_moca, mean_no_rbd_moca, std_no_rbd_moca, mean_rbd_moca, std_rbd_moca = calculate_stat_metadata(pd_cohort_non_pd_no_rbd, pd_cohort_non_pd_rbd, 'MOCA')
    t_stat_ess, p_ttest_ess, u_stat_ess, p_mann_ess, mean_no_rbd_ess, std_no_rbd_ess, mean_rbd_ess, std_rbd_ess  = calculate_stat_metadata(pd_cohort_non_pd_no_rbd, pd_cohort_non_pd_rbd, 'ESS')
    t_stat_q, p_ttest_q, u_stat_q, p_mann_q, mean_no_rbd_q, std_no_rbd_q, mean_rbd_q, std_rbd_q = calculate_stat_metadata(pd_cohort_non_pd_no_rbd, pd_cohort_non_pd_rbd, 'RBDQ')
    return num_subjects, num_non_pd, num_non_pd_rbd,night_count_non_pd, subjects_label_non_pd, female_num_rbd, \
           female_num_no_rbd, t_stat_age, t_stat_updrs, t_stat_moca, t_stat_ess, t_stat_q, pd_cohort_non_pd_rbdq

def calculate_stat_metadata(df_no_rbd, df_rbd, column_name):
    new_df_rbd = df_rbd[~np.isnan(df_rbd[column_name])]
    new_df_no_rbd = df_no_rbd[~np.isnan(df_no_rbd[column_name])]
    t_stat, p_value_ttest = stats.ttest_ind(new_df_rbd[column_name], new_df_no_rbd[column_name])
    u_stat, p_value_mann = stats.mannwhitneyu(new_df_rbd[column_name], new_df_no_rbd[column_name])
    mean_no_rbd = np.mean(df_no_rbd[column_name])
    std_no_rbd = np.std(df_no_rbd[column_name])
    mean_rbd = np.mean(df_rbd[column_name])
    std_rbd = np.std(df_rbd[column_name])
    return t_stat, p_value_ttest, u_stat, p_value_mann, mean_no_rbd, std_no_rbd, mean_rbd, std_rbd

def norm_df_features(df_features):
    x = df_features.values
    scaler = MinMaxScaler()
    x_scaled = scaler.fit_transform(x)
    df_features_norm = pd.DataFrame(x_scaled, columns=df_features.columns, index=df_features.index)
    return df_features_norm


def calculate_corr_features_label(df_features, df_clean, label_str):
    df_features_label = df_features.copy()
    df_features_label[label_str] = df_clean[label_str]
    corr_mat_label = np.abs(df_features_label.corr()[label_str])
    sort_corr = corr_mat_label.sort_values()
    return sort_corr


def remove_correlated_features(df_features, df_full, label_str, corr_thr):
    # Calculate correlation
    corr_mat_features_rbd = calculate_corr_features_label(df_features, df_full, label_str)
    corr_features = df_features.corr()
    high_corr_pairs = (corr_features.abs() > corr_thr) & (corr_features != 1.0)
    # Find pairs of highly correlated features
    high_corr_features = []
    for i in range(len(corr_features.columns)):
        for j in range(i):
            if high_corr_pairs.iloc[i, j]:
                high_corr_features.append((corr_features.columns[i], corr_features.columns[j]))
    features_to_remove = []
    for features_pairs in high_corr_features:
        if corr_mat_features_rbd[features_pairs[0]] > corr_mat_features_rbd[features_pairs[1]]:
            features_to_remove.append(features_pairs[1])
        else:
            features_to_remove.append(features_pairs[0])

    list_features_to_remove = list(set(features_to_remove))
    new_df_features = df_features.drop(columns=list_features_to_remove)
    return new_df_features


def pca_calculation(x, y, label_str):
    pca = PCA(n_components=3)
    principalComponents = pca.fit_transform(x)
    principalDf = pd.DataFrame(data=principalComponents,
                               columns=['principal component 1', 'principal component 2', 'principal component 3'])
    y.reset_index(drop=True, inplace=True)
    finalDf = pd.concat([principalDf, y], axis=1)
    # Create a 3D scatter plot
    fig = plt.figure(figsize=(10, 7))
    ax = fig.add_subplot(111, projection='3d')
    if label_str == 'Night label':
        ax.scatter(finalDf.loc[np.where([finalDf['Night label'] == 'Lab'])[1], 'principal component 1'],
                   finalDf.loc[np.where([finalDf['Night label'] == 'Lab'])[1], 'principal component 2'],
                   finalDf.loc[np.where([finalDf['Night label'] == 'Lab'])[1], 'principal component 3'], c='g', s=50)
        ax.scatter(finalDf.loc[np.where([finalDf['Night label'] == 'Home'])[1], 'principal component 1'],
                   finalDf.loc[np.where([finalDf['Night label'] == 'Home'])[1], 'principal component 2'],
                   finalDf.loc[np.where([finalDf['Night label'] == 'Home'])[1], 'principal component 3'], c='royalblue', s=50)
        ax.set_title('3D PCA of Night label')
        ax.legend(['Lab', 'Home'])
    else:
        ax.scatter(finalDf.loc[(finalDf[label_str] > 0), 'principal component 1'],
                   finalDf.loc[(finalDf[label_str] > 0), 'principal component 2'],
                   finalDf.loc[(finalDf[label_str] > 0), 'principal component 3'], c='sandybrown', s=50)
        ax.scatter(finalDf.loc[(finalDf[label_str] < 1), 'principal component 1'],
                   finalDf.loc[(finalDf[label_str] < 1), 'principal component 2'],
                   finalDf.loc[(finalDf[label_str] < 1), 'principal component 3'], c='cornflowerblue', s=50)
        ax.set_title('3D PCA of ' + label_str)
        ax.legend([label_str, 'No ' + label_str])
    ax.set_xlabel('Principal Component 1', fontsize=10)
    ax.set_ylabel('Principal Component 2', fontsize=10)
    ax.set_zlabel('Principal Component 3', fontsize=10)
    ax.grid()
    plt.show()


def SHAP_analysis(df_features, df_full):
    X = df_features
    y = df_full[['RBD']]
    importance_score = pd.DataFrame({'Feature name': X.columns})
    for i in range(0, 5):
        model = DecisionTreeClassifier(max_depth=4).fit(X, y)
        explainer = shap.Explainer(model, X)
        shap_values = explainer.shap_values(X)
        feature_importance = np.abs(shap_values).mean(axis=0)
        importance_score['Model ' + str(i)] = feature_importance[:, 0]

    importance_score['Total'] = [np.sum(importance_score.iloc[row, 1:].to_list()) for row in range(0, len(importance_score))]
    score_sorted = importance_score.sort_values(by='Total', ascending=False)
    return score_sorted


def split_train_test_home_lab(df_features, df_clean, label_str):
    x_train = df_features[df_clean['Night label'] == 'Lab']
    x_test = df_features[df_clean['Night label'] == 'Home']
    y_train = df_clean[df_clean['Night label'] == 'Lab'][label_str]
    y_test = df_clean[df_clean['Night label'] == 'Home'][label_str]
    df_results = df_clean[df_clean['Night label'] == 'Home'].iloc[:, 0:4]
    return x_train, x_test, y_train, y_test, df_results


def split_train_test_home_idx_night(df_features, df_clean, label_str, night_idx):
    x_train = df_features[(df_clean['Night label'] == 'Home') & (df_clean['Night index'] == night_idx)]
    y_train = df_clean[(df_clean['Night label'] == 'Home') & (df_clean['Night index'] == night_idx)][label_str]
    x_test = df_features[df_clean['Night index'] != night_idx]
    y_test = df_clean[df_clean['Night index'] != night_idx][label_str]
    df_results = df_clean[df_clean['Night index'] != night_idx].iloc[:, 0:4]
    return x_train, x_test, y_train, y_test, df_results


def build_models():
    reg = LogisticRegression(penalty='l1', solver='saga', max_iter=1000, random_state=42)
    svm = SVC(kernel='rbf', gamma='scale', class_weight="balanced", C=1, probability=True, random_state=42)
    gbc = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, max_depth=5, min_samples_leaf=5, random_state=42)
    rf = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=2, criterion='gini', random_state=42)
    models = [reg, svm rf, gbc]
    return models


def optimized_hyperparameters(model, x_train, y_train):
    if type(model).__name__ == 'GradientBoostingClassifier':
        param_grid = {
            'n_estimators': [50, 100, 200, 400],
            'learning_rate': [0.01, 0.1, 0.2, 0.4],
            'max_depth': [3, 5, 10],
            'min_samples_leaf': [1, 2, 5]}
    elif type(model).__name__ == 'RandomForestClassifier':
        param_grid = {
            'n_estimators': [50, 100, 200, 400],
            'criterion' : ['gini', 'entropy'],
            'max_depth': [3, 5, 10],
            'min_samples_leaf': [1, 2, 5]}
    elif type(model).__name__ == 'SVC':
        param_grid = {
            'kernel' = ["linear", "rbf", "poly"],
            'C' = [0.1, 1, 10]
            'class_weight': 'balanced'}
    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)
    grid_search.fit(x_train, y_train)
    print("Best hyperparameters:", grid_search.best_params_)
    print("Best cross-validation score:", grid_search.best_score_)
    return grid_search.best_params_


def evaluate_model(model, x_train, y_train, x_test, y_test):
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    probabilities = model.predict_proba(x_test)
    f1_score_model = f1_score(y_test, y_pred, average='weighted')
    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)
    return y_pred, accuracy, conf_matrix, probabilities, f1_score_model, balanced_accuracy


def feature_selection_rfe(x_train, y_train, num_features):
    estimator = DecisionTreeClassifier()
    selector = RFECV(estimator, step=0.7, cv=5, min_features_to_select=num_features)
    output = selector.fit(x_train, y_train)
    feature_ranking = pd.DataFrame({'Feature': x_train.columns, 'Ranking': selector.ranking_})
    return x_train.columns[np.where(output.support_)[0]], feature_ranking


def pipeline_run_models(df_features, df_clean, label_str, features=None, night_idx=None):

    # Split data to Train and Test
    if subject_idx is not None:
        if night_test is not None:
            x_train, x_test, y_train, y_test, df_results = split_train_test_home_loo_night_test(df_features, df_clean, label_str, subject_idx, night_idx, night_test, night_label)
        elif night_idx is not None:
            x_train, x_test, y_train, y_test, df_results = split_train_test_home_loo_night_idx(df_features, df_clean, label_str, subject_idx, night_idx)
        else:
            x_train, x_test, y_train, y_test, df_results = split_train_test_loo(df_features, df_clean, label_str, night_label, subject_idx)
    else:
        print("Please enter the Train dataset settings")
        return

    # Build models and evaluate model per night
    models = build_models()
    models_score = {}
    for model in models:
        if features is not None:
            selected_features = features
        else:
            selected_features, feature_ranking = feature_selection_rfe(x_train, y_train, 4)
            print(selected_features)
        best_params = optimized_hyperparameters(model, x_train, y_train)
        model_name = type(model).__name__
        y_pred, accur, conf, probs, f1, balanced_acc = evaluate_model(model, x_train.loc[:, selected_features], y_train,
                                                                      x_test.loc[:, selected_features], y_test)
        df_results[label_str + ' detection ' + str(model_name)] = y_pred
        df_results[label_str + ' probability ' + str(model_name)] = probs[:, 0]

    # Evaluate models per subject
    df_label_per_subject = df_results.iloc[:, 0:4].groupby(['Subject ID']).max()
    df_results_per_subject = df_results.iloc[:, [0, 4, 6, 8]].groupby(['Subject ID']).sum()
    df_per_subject = pd.concat([df_label_per_subject, df_results_per_subject], axis=1)
    for model in models:
        model_name = type(model).__name__
        column_model = label_str + ' detection ' + str(model_name)
        df_per_subject.loc[df_per_subject[column_model] > 0, column_model] = 1
        accuracy = accuracy_score(df_per_subject[label_str], df_per_subject[column_model])
        conf_matrix = confusion_matrix(df_per_subject[label_str], df_per_subject[column_model])
        f1_score_model = f1_score(df_per_subject[label_str], df_per_subject[column_model], average='weighted')
        balanced_accuracy = balanced_accuracy_score(df_per_subject[label_str], df_per_subject[column_model])
        models_score[model_name + ' accuracy'] = accuracy
        models_score[model_name + ' F1 score'] = f1_score_model
        models_score[model_name + ' balanced accuracy score'] = balanced_accuracy
        print(conf_matrix)

    return df_results, models_score


def run_model_set_night_num_in_dataset(df_features, df_full, num_of_nights, night_env, night_index=None, set_features=None):
    if night_env == 'Home':
        df_results, models_score = pipeline_run_models(df_features[df_full['Night index'] < num_of_nights],
                                                   df_full[df_full['Night index'] < num_of_nights], 'RBD',
                                                   night_idx=night_index, features=set_features)
    elif night_env == 'Lab':
        df_results, models_score = pipeline_run_models(df_features[df_full['Night index'] < num_of_nights],
                                                    df_full[df_full['Night index'] < num_of_nights], 'RBD',
                                                    night_idx='Lab', features=set_features)
    else:
        return None, None
    return df_results, models_score


def pipeline_run_change_test_dataset(df_all, df_features, best_features, nights_num, night_idx=None,night_label=None, night_test=None):
    df_results, models_score = pipeline_run_models(df_features[df_all['Night index'] < nights_num],
                                                   df_all[df_all['Night index'] < nights_num],'RBD',
                                                   night_idx=night_idx, night_label=night_label,
                                                   night_test=night_test, features=best_features)
    return df_results, models_score



if __name__ == '__main__':
    ''' Load data and clean '''
    df = pd.read_excel('All_features.xlsx')
    # Remove corrupted data
    df_clean = clean_df_tst_na(df)
    # Clean meta data
    df_features_raw = df_clean.iloc[:, 9:]
    # Normalized features
    df_features_norm = norm_df_features(df_features_raw)

    '''Excluding PD subjects'''
    df_full = df_clean.loc[df_clean['PD'] == 0, :]
    df_features = df_features_norm.loc[df_clean['PD'] == 0, :]

    ''' Calculate stat and demograpic '''
    num_subjects, num_non_pd, num_non_pd_rbd, night_count_non_pd, subjects_label_non_pd,\
    female_num_rbd, female_num_no_rbd, t_stat_age, t_stat_updrs, t_stat_moca, \
    t_stat_ess, t_stat_q, pd_cohort_non_pd_rbdq = calculate_stat_demograpic(df_clean,df_healthy)

    ''' Features elimination '''
    new_df_features = remove_correlated_features(df_features, df_full, 'RBD', 0.8)

    ''' PCA analysis '''
    # Home vs Lab
    pca_calculation(new_df_features, df_full[['Night label']], 'Night label')
    # RBD vs non - RBD
    pca_calculation(new_df_features, df_full[['RBD']], 'RBD')

    # SHAP analysis (Supplementary)
    importance_score = SHAP_analysis(new_df_features, df_full)

    ''' Run models '''

    ''' Leave one out '''
    subject_id_list = subjects_label_non_pd.index.to_list()
    results_by_night_idx = []

    for night_label in ['Home','Lab']:
        for thr in [0.4,0.5,0.6]:
            for night_idx in range(1,7):
                dict_loo_results = {'Subject ID': [], 'RBD': [], 'Detection LogisticReg': [], 'Detection RFC': [],
                                    'Detection SVM': [], 'Detection GBC': [],'RBDQ' : []}
                df_loo_all_nights = pd.DataFrame()
                for idx in subject_id_list:
                    ''' Change number of nights included in test'''
                    df_results_idx, models_score_idx = pipeline_run_models(thr, df_features_healthy, df_healthy, 'RBD',
                                                                           subject_idx=idx, night_label=night_label,
                                                                           night_test=night_idx, features=best_features)
                    ''' Change the train night index 
                    df_results_idx, models_score_idx = pipeline_run_models(df_features_healthy, df_healthy, 'RBD', subject_idx=idx,
                                                                           night_idx=night_idx, night_label=night_label, features=best_features)'''

                    ''' train all nights at home 
                    df_results_idx, models_score_idx = pipeline_run_models(df_features_healthy, df_healthy, 'RBD', subject_idx=idx,
                                                                            night_label=night_label, features=best_features)'''

                    dict_loo_results['Subject ID'].append(idx)
                    dict_loo_results['RBD'].append(subjects_label_non_pd.loc[idx,'RBD'])
                    dict_loo_results['Detection LogisticReg'].append(np.max(df_results_idx['RBD detection LogisticRegression']))
                    dict_loo_results['Detection RFC'].append(np.max(df_results_idx['RBD detection RandomForestClassifier']))
                    dict_loo_results['Detection SVM'].append(np.max(df_results_idx['RBD detection SVC']))
                    dict_loo_results['Detection GBC'].append(np.max(df_results_idx['RBD detection GradientBoostingClassifier']))
                    dict_loo_results['RBDQ'].append(pd_cohort_non_pd_rbdq.loc[pd_cohort_non_pd_rbdq['Subject ID'] == idx,'RBDQ'].values[0])
                    df_loo_all_nights = pd.concat([df_loo_all_nights, df_results_idx])
                df_loo_results = pd.DataFrame(dict_loo_results)
                conf_mat_log = confusion_matrix(df_loo_results['RBD'], df_loo_results["Detection LogisticReg"])
                conf_mat_svm = confusion_matrix(df_loo_results['RBD'], df_loo_results["Detection SVM"])
                conf_mat_gcb = confusion_matrix(df_loo_results['RBD'], df_loo_results["Detection GBC"])
                conf_mat_rfc = confusion_matrix(df_loo_results['RBD'], df_loo_results["Detection RFC"])
                results_by_night_idx.append(
                        {"Label": night_label, "Threshold": thr, "Night idx": night_idx,
                         "Predicted RBD Logistic": conf_mat_log[1, 1], "Predicted No RBD Logistic": conf_mat_log[0, 0],
                         "Predicted RBD SVM": conf_mat_svm[1, 1], "Predicted No RBD SVM": conf_mat_svm[0, 0],
                         "Predicted RBD GBC": conf_mat_gcb[1, 1], "Predicted No GBC": conf_mat_gcb[0, 0],
                         "Predicted RBD RFD": conf_mat_rfc[1, 1], "Predicted No RFD": conf_mat_rfc[0, 0],
                         })

                cm_percentage = conf_mat_svm.astype('float') / conf_mat_svm.sum(axis=1)[:, np.newaxis] * 100
                disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=[0, 1])
                if night_label == 'Home':
                    cmap = 'Blues'
                else:
                    cmap = 'Greens'
                    disp.plot(cmap=cmap, values_format='.0f')
                    plt.xlabel('Predicted\nTrained on night at ' + night_label, fontsize=14, loc='center')
                    plt.ylabel('True iRBD', fontsize=14)
                    plt.show(block=True)



    ''' Model performance vs number of nights included in test dataset '''
    best_features = ['LIB bin 1 thr 300_time', 'TA bin 1 t0.05_w15', 'Mean activity count bin 1 (2-5 am)', 'Mean AP bin 30']
    # Model trained on night at home -
    df_results_2, models_score_2 = run_model_set_night_num_in_dataset(df_features, df_full, 3, 'Home', 1, best_features)
    df_results_3, models_score_3 = run_model_set_night_num_in_dataset(df_features, df_full, 4, 'Home', 1, best_features)
    df_results_4, models_score_4 = run_model_set_night_num_in_dataset(df_features, df_full, 5, 'Home', 1, best_features)
    df_results_5, models_score_5 = run_model_set_night_num_in_dataset(df_features, df_full, 6, 'Home', 1, best_features)
    df_results_6, models_score_6 = run_model_set_night_num_in_dataset(df_features, df_full, 7, 'Home', 1, best_features)
    df_results_7, models_score_7 = run_model_set_night_num_in_dataset(df_features, df_full, 8, 'Home', 1, best_features)
    # Models trained on night at lab
    df_results_2_lab, models_score_2_lab = run_model_set_night_num_in_dataset(df_features, df_full, 3, 'Lab', set_features=best_features)
    df_results_3_lab, models_score_3_lab = run_model_set_night_num_in_dataset(df_features, df_full, 4, 'Lab', set_features=best_features)
    df_results_4_lab, models_score_4_lab = run_model_set_night_num_in_dataset(df_features, df_full, 5, 'Lab', set_features=best_features)
    df_results_5_lab, models_score_5_lab = run_model_set_night_num_in_dataset(df_features, df_full, 6, 'Lab', set_features=best_features)
    df_results_6_lab, models_score_6_lab = run_model_set_night_num_in_dataset(df_features, df_full, 7, 'Lab', set_features=best_features)
    df_results_7_lab, models_score_7_lab = run_model_set_night_num_in_dataset(df_features, df_full, 8, 'Lab', set_features=best_features)

